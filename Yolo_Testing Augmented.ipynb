{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vD_O2xpN_jmL"
      },
      "source": [
        "Summary of available models:\n",
        "\n",
        "- yolov8n (Done)\n",
        "- yolov8s (Done)\n",
        "- yolov8m (Done)\n",
        "- yolov8l (Done)\n",
        "- yolov8x (Done)\n",
        "- yolov5n (Done)\n",
        "- yolov5s (Done)\n",
        "- yolov5m (Done)\n",
        "- yolov5l (Done)\n",
        "- yolov5x (done)\n",
        "- yolov3 (Done)\n",
        "- yolov3u (Done)\n",
        "- yolov3-spp (Done)\n",
        "- yolov3-tiny (Done)\n",
        "\n",
        "For More Epoch :\n",
        "- yolov3u (100) (Done)\n",
        "- yolov5x (100) (Failed (No Runtime exceed limit)) - Res 75\n",
        "- yolov8x (100) (No Computing Unit available) - Res 75"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8PFm9AcKqe8Y",
        "outputId": "0e409d8b-7b1d-4c3d-ca87-f7b1177fcfc6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "YAML Path: ./Dataset\\YOLODatasetFull\\dataset.yaml\n",
            "Results Directory: ./results\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Define paths for local environment\n",
        "local_base_path = \"./\"  # Current directory\n",
        "yaml_path = os.path.join(local_base_path, \"Dataset\", \"YOLODatasetFull\", \"dataset.yaml\")  # Path to your YAML file\n",
        "results_dir = os.path.join(local_base_path, \"results\")       # Directory to save results\n",
        "os.makedirs(results_dir, exist_ok=True)\n",
        "\n",
        "# Print the paths to confirm\n",
        "print(f\"YAML Path: {yaml_path}\")\n",
        "print(f\"Results Directory: {results_dir}\")\n",
        "\n",
        "# **Important Considerations:**\n",
        "\n",
        "# 1.  **Dataset Location:**\n",
        "#     * Ensure that your dataset is located in the  `./Dataset/YOLODatasetFull`  directory, relative to where you run this Python script.  If your dataset is in a different location, you'll need to adjust the  `local_base_path`  or  `yaml_path`  variables accordingly.\n",
        "#     * The script assumes your `dataset.yaml` is inside the `YOLODatasetFull` folder.\n",
        "#\n",
        "# 2.  **YAML File Content:**\n",
        "#     * The `dataset.yaml` file should contain the correct paths to your training and validation data.  If these paths are absolute paths (e.g.,  `/content/drive/...`), you'll need to change them to relative paths that are valid in your local environment.\n",
        "#\n",
        "# 3. **results directory:**\n",
        "#     * The results directory is now created at the root level of your project\n",
        "\n",
        "# Example `dataset.yaml` structure (check and modify as needed):\n",
        "# ```yaml\n",
        "# train: ./Dataset/YOLODatasetFull/train/images\n",
        "# val: ./Dataset/YOLODatasetFull/valid/images\n",
        "# test: ./Dataset/YOLODatasetFull/test/images  # If you have a test set\n",
        "# nc: 80  # Number of classes\n",
        "# names: ['class1', 'class2', ..., 'class80']  # Class names\n",
        "# ```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IloKysuTpqwA",
        "outputId": "1d542cc7-567c-4b5d-ca01-6f456ff52c13"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from ultralytics import YOLO\n",
        "from tqdm import tqdm\n",
        "from datetime import datetime\n",
        "import time\n",
        "\n",
        "# Paths\n",
        "local_base_path = \"./\"  # Current directory\n",
        "yaml_path = os.path.join(local_base_path, \"Dataset\", \"YOLODatasetFull\", \"dataset.yaml\")\n",
        "results_dir = os.path.join(local_base_path, \"results\")\n",
        "os.makedirs(results_dir, exist_ok=True)\n",
        "\n",
        "#epoch = 12\n",
        "#epoch = 100\n",
        "# epoch = 75\n",
        "epoch = 50\n",
        "\n",
        "# imagesize = 640\n",
        "imagesize = 512\n",
        "\n",
        "# batchs = 20 # Maximum For Yolo v3 (14,8 GB Peak)\n",
        "# batchs = 16 # Maximum For Yolo v5x (14,8 GB Peak)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Augmented"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import cv2\n",
        "import albumentations as A\n",
        "from collections import defaultdict\n",
        "\n",
        "image_dir = \"./Dataset/YOLODatasetFull/train/images\"\n",
        "label_dir = \"./Dataset/YOLODatasetFull/train/labels\"\n",
        "\n",
        "augment = A.Compose([\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.RandomBrightnessContrast(p=0.5),\n",
        "    A.GaussNoise(p=0.3),\n",
        "    A.Rotate(limit=10, p=0.5)\n",
        "], bbox_params=A.BboxParams(format='yolo', label_fields=['class_labels']))\n",
        "\n",
        "# Count samples per class\n",
        "class_counts = defaultdict(int)\n",
        "label_files = [f for f in os.listdir(label_dir) if f.endswith('.txt')]\n",
        "for lf in label_files:\n",
        "    with open(os.path.join(label_dir, lf), 'r') as f:\n",
        "        for line in f:\n",
        "            class_id = line.strip().split()[0]\n",
        "            class_counts[class_id] += 1\n",
        "\n",
        "min_count = min(class_counts.values())\n",
        "target_count = max(min_count * 2, 20)\n",
        "\n",
        "for class_id, count in class_counts.items():\n",
        "    if count >= target_count:\n",
        "        continue\n",
        "    needed = target_count - count\n",
        "    print(f\"Augmenting class {class_id}: need {needed} more samples\")\n",
        "    matching_files = []\n",
        "    for lf in label_files:\n",
        "        with open(os.path.join(label_dir, lf), 'r') as f:\n",
        "            for line in f:\n",
        "                if line.strip().split()[0] == class_id:\n",
        "                    matching_files.append(lf)\n",
        "                    break\n",
        "\n",
        "    for i in range(needed):\n",
        "        src_label = random.choice(matching_files)\n",
        "        src_image = src_label.replace('.txt', '.jpg')\n",
        "        img_path = os.path.join(image_dir, src_image)\n",
        "        lbl_path = os.path.join(label_dir, src_label)\n",
        "\n",
        "        image = cv2.imread(img_path)\n",
        "        if image is None:\n",
        "            continue\n",
        "        with open(lbl_path, 'r') as f:\n",
        "            lines = f.readlines()\n",
        "        boxes = []\n",
        "        classes = []\n",
        "        for line in lines:\n",
        "            parts = line.strip().split()\n",
        "            if parts[0] == class_id:\n",
        "                x, y, bw, bh = map(float, parts[1:])\n",
        "                boxes.append([x, y, bw, bh])\n",
        "                classes.append(class_id)\n",
        "\n",
        "        if not boxes:\n",
        "            continue\n",
        "        augmented = augment(image=image, bboxes=boxes, class_labels=classes)\n",
        "        aug_img = augmented['image']\n",
        "        aug_boxes = augmented['bboxes']\n",
        "\n",
        "        save_img_name = src_image.replace('.jpg', f'_aug{i}.jpg')\n",
        "        save_lbl_name = src_label.replace('.txt', f'_aug{i}.txt')\n",
        "        cv2.imwrite(os.path.join(image_dir, save_img_name), aug_img)\n",
        "        with open(os.path.join(label_dir, save_lbl_name), 'w') as f:\n",
        "            for box in aug_boxes:\n",
        "                f.write(f\"{class_id} {' '.join([f'{v:.6f}' for v in box])}\\\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFUjvfog0hNE"
      },
      "source": [
        "# YOLOv\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nLQw6mwFrCJo",
        "outputId": "ea0c28d0-bb6c-4e25-dc1d-22250e2cb798"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training and evaluating YOLOv8l...\n",
            "Ultralytics 8.3.123  Python-3.12.1 torch-2.5.0+cu124 CUDA:0 (NVIDIA GeForce RTX 2050, 4096MiB)\n",
            "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8l.pt, data=./Dataset\\YOLODatasetFull\\dataset.yaml, epochs=50, time=None, patience=100, batch=8, imgsz=512, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=YOLOv8l_detection, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, cutmix=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\YOLOv8l_detection\n",
            "Overriding model.yaml nc=80 with nc=4\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
            "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n",
            "  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n",
            "  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n",
            "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            "  8                  -1  3   4461568  ultralytics.nn.modules.block.C2f             [512, 512, 3, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  3   1247744  ultralytics.nn.modules.block.C2f             [768, 256, 3]                 \n",
            " 16                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  3   4592640  ultralytics.nn.modules.block.C2f             [768, 512, 3]                 \n",
            " 19                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
            " 22        [15, 18, 21]  1   5585884  ultralytics.nn.modules.head.Detect           [4, [256, 512, 512]]          \n",
            "Model summary: 209 layers, 43,632,924 parameters, 43,632,908 gradients, 165.4 GFLOPs\n",
            "\n",
            "Transferred 589/595 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs\\detect\\YOLOv8l_detection', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 1485.1458.7 MB/s, size: 270.3 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\Pongo\\OneDrive\\Documents\\~Cornel\\~Ideas n Innovation\\Project\\25-4-22 -- Parkinson Unika\\Dataset\\YOLODatasetFull\\labels\\train.cache... 2985 images, 0 backgrounds, 0 corrupt: 100%|██████████| 2985/2985 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 534.6290.0 MB/s, size: 183.3 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Pongo\\OneDrive\\Documents\\~Cornel\\~Ideas n Innovation\\Project\\25-4-22 -- Parkinson Unika\\Dataset\\YOLODatasetFull\\labels\\val.cache... 747 images, 0 backgrounds, 0 corrupt: 100%|██████████| 747/747 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Plotting labels to runs\\detect\\YOLOv8l_detection\\labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.00125, momentum=0.9) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added \n",
            "Image sizes 512 train, 512 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1mruns\\detect\\YOLOv8l_detection\u001b[0m\n",
            "Starting training for 50 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       1/50      3.99G      0.341      1.255      1.045          4        512: 100%|██████████| 374/374 [08:31<00:00,  1.37s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 47/47 [01:11<00:00,  1.52s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        747        747      0.327      0.612      0.359       0.21\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       2/50      3.77G     0.3162      1.021     0.9994          4        512: 100%|██████████| 374/374 [08:58<00:00,  1.44s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 47/47 [01:38<00:00,  2.09s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        747        747      0.146      0.255      0.134     0.0448\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       3/50      3.77G     0.2726     0.9403     0.9762          2        512: 100%|██████████| 374/374 [03:53<00:00,  1.60it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 47/47 [00:34<00:00,  1.37it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        747        747      0.587      0.777      0.696       0.67\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       4/50      3.78G     0.2408     0.8446     0.9592          2        512: 100%|██████████| 374/374 [04:01<00:00,  1.55it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 47/47 [01:33<00:00,  1.99s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        747        747       0.51      0.841      0.697      0.695\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       5/50      3.77G     0.2015     0.8006     0.9397          4        512: 100%|██████████| 374/374 [04:04<00:00,  1.53it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 47/47 [00:47<00:00,  1.01s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        747        747       0.67      0.786      0.781      0.764\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       6/50      3.78G      0.191      0.763     0.9403          2        512: 100%|██████████| 374/374 [04:17<00:00,  1.45it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 47/47 [01:46<00:00,  2.27s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        747        747      0.513      0.732      0.623      0.587\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       7/50       3.7G     0.1691     0.7387     0.9312          2        512: 100%|██████████| 374/374 [03:27<00:00,  1.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 47/47 [00:54<00:00,  1.15s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        747        747       0.69       0.82      0.816      0.808\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       8/50      3.77G     0.1544     0.7145     0.9244          1        512: 100%|██████████| 374/374 [06:59<00:00,  1.12s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 47/47 [00:44<00:00,  1.06it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        747        747      0.692      0.785      0.781      0.774\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       9/50      3.77G     0.1473     0.6762     0.9214          3        512: 100%|██████████| 374/374 [06:15<00:00,  1.00s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 47/47 [01:31<00:00,  1.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        747        747      0.667      0.859      0.801      0.797\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      10/50      3.77G     0.1354      0.648     0.9179          2        512: 100%|██████████| 374/374 [03:52<00:00,  1.61it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 47/47 [01:50<00:00,  2.36s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        747        747      0.645      0.765      0.746      0.736\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      11/50      3.68G     0.1292     0.6637     0.9149          4        512: 100%|██████████| 374/374 [03:06<00:00,  2.00it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 47/47 [00:50<00:00,  1.08s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        747        747      0.739      0.829      0.846      0.836\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      12/50      3.77G     0.1215     0.6368     0.9126          2        512: 100%|██████████| 374/374 [06:48<00:00,  1.09s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 47/47 [00:55<00:00,  1.18s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        747        747      0.618      0.882       0.82      0.813\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      13/50      3.77G     0.1243      0.631     0.9119          4        512: 100%|██████████| 374/374 [06:12<00:00,  1.00it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 47/47 [01:27<00:00,  1.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        747        747      0.712      0.805       0.83      0.815\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      14/50      3.77G     0.1177     0.6282     0.9069          1        512: 100%|██████████| 374/374 [07:23<00:00,  1.19s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 47/47 [02:05<00:00,  2.67s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        747        747      0.748      0.824      0.815      0.788\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      15/50      3.72G     0.1118     0.5996     0.9092          4        512: 100%|██████████| 374/374 [03:50<00:00,  1.62it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 47/47 [01:02<00:00,  1.34s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        747        747      0.709      0.789      0.792      0.745\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      16/50      3.78G     0.1141     0.6024     0.9081          4        512: 100%|██████████| 374/374 [06:55<00:00,  1.11s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 47/47 [01:27<00:00,  1.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        747        747      0.744      0.856      0.841      0.832\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      17/50      3.77G     0.1111     0.6066     0.9032          4        512: 100%|██████████| 374/374 [05:29<00:00,  1.14it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 47/47 [00:51<00:00,  1.09s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        747        747       0.71      0.861      0.825      0.825\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      18/50      3.77G     0.1119     0.5931     0.9112          2        512: 100%|██████████| 374/374 [04:03<00:00,  1.53it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 47/47 [01:57<00:00,  2.51s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        747        747      0.757      0.823      0.811       0.81\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      19/50      3.61G     0.0988     0.5708     0.9065          4        512: 100%|██████████| 374/374 [03:13<00:00,  1.93it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 47/47 [00:49<00:00,  1.06s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        747        747      0.756      0.844      0.844      0.844\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      20/50      3.76G    0.09679     0.5568     0.8982          4        512: 100%|██████████| 374/374 [06:28<00:00,  1.04s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 47/47 [01:29<00:00,  1.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        747        747      0.702      0.856      0.819      0.819\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      21/50      3.78G     0.1018     0.5673      0.912          2        512: 100%|██████████| 374/374 [05:49<00:00,  1.07it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 47/47 [01:06<00:00,  1.41s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        747        747      0.778      0.792      0.829      0.828\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      22/50      3.77G    0.09641     0.5467     0.9067          2        512: 100%|██████████| 374/374 [06:04<00:00,  1.02it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  60%|█████▉    | 28/47 [01:13<00:55,  2.91s/it]"
          ]
        }
      ],
      "source": [
        "# Metrics storage\n",
        "metrics = {}\n",
        "\n",
        "# Remmeber to change the batch !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
        "# batch01 = 4 # Reccomended Low for 2050 RTX 4GB YOLOv3\n",
        "batch01 = 8 # Reccomended High for 2050 RTX 4GB\n",
        "# batch01 = 12 # High for 2050 RTX 4GB\n",
        "\n",
        "# Model to train and evaluate\n",
        "model_name = \"YOLOv8l\"       # Change this to the model you want to train (e.g., YOLOv4, YOLOv5x)\n",
        "model_path = \"yolov8l.pt\"    # Pretrained model path for YOLOv3 (update as needed)\n",
        "\n",
        "# Generate unique directory name based on model and current time\n",
        "current_time = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "results_dirs = os.path.join(results_dir, f\"{current_time}, {model_name} with E-B {epoch}-{batch01}\")\n",
        "os.makedirs(results_dirs, exist_ok=True)  # Create the directory if it doesn't exist\n",
        "\n",
        "# Train and Evaluate the Model\n",
        "print(f\"\\nTraining and evaluating {model_name}...\")\n",
        "\n",
        "# Start time tracking\n",
        "start_time = time.time()\n",
        "\n",
        "# Train the model\n",
        "model = YOLO(model_path)  # Load pre-trained model\n",
        "model.train(\n",
        "    task=\"detect\",\n",
        "    data=yaml_path,\n",
        "    epochs=epoch,  # Set epochs for quick testing; increase for better results\n",
        "    imgsz=imagesize,\n",
        "    batch=batch01,  # Adjust to fit your GPU memory\n",
        "    name=f\"{model_name}_detection\",\n",
        "    save_dir=os.path.join(results_dirs, model_name)\n",
        ")\n",
        "# End time tracking\n",
        "end_time = time.time()\n",
        "training_duration_hours = (end_time - start_time) / 3600  # Convert seconds to hours\n",
        "print(f\"Model and results saved to: {results_dir}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C7HEDvXImUum"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results successfully moved to: ./results\\2025-05-07_17-23-35, YOLOv5l with E-B 50-8\\YOLOv5l\n"
          ]
        }
      ],
      "source": [
        "import shutil\n",
        "\n",
        "source_dir = f\"runs/detect/\"\n",
        "destination_dir = os.path.join(results_dirs, model_name)\n",
        "\n",
        "# Move the directory\n",
        "if os.path.exists(source_dir):\n",
        "    shutil.move(source_dir, destination_dir)\n",
        "    print(f\"Results successfully moved to: {destination_dir}\")\n",
        "else:\n",
        "    print(f\"Source directory not found: {source_dir}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nl3JAzzyfRfs"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics 8.3.123  Python-3.12.1 torch-2.5.0+cu124 CUDA:0 (NVIDIA GeForce RTX 2050, 4096MiB)\n",
            "YOLOv5l summary (fused): 128 layers, 53,134,492 parameters, 0 gradients, 134.7 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 1019.8813.6 MB/s, size: 109.0 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Pongo\\OneDrive\\Documents\\~Cornel\\~Ideas n Innovation\\Project\\25-4-22 -- Parkinson Unika\\Dataset\\YOLODatasetFull\\labels\\val.cache... 747 images, 0 backgrounds, 0 corrupt: 100%|██████████| 747/747 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 94/94 [00:28<00:00,  3.30it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        747        747      0.747      0.866      0.858      0.855\n",
            "        healthy spiral        112        112      0.502      0.856      0.635       0.63\n",
            "          healthy wave        198        198      0.903      0.889       0.95      0.949\n",
            "      parkinson spiral        285        285      0.847      0.758      0.923      0.917\n",
            "        parkinson wave        152        152      0.735      0.961      0.925      0.924\n",
            "Speed: 0.2ms preprocess, 34.6ms inference, 0.0ms loss, 0.9ms postprocess per image\n",
            "Results saved to \u001b[1mruns\\detect\\YOLOv5l_detection2\u001b[0m\n",
            "\n",
            "Metrics:\n",
            "Model: YOLOv5l\n",
            "Validation Time: 2025-05-08 00-06-26\n",
            "\n",
            "Training Duration: 6.698 hours for 50 epochs\n",
            "\n",
            "AP50: 0.8580\n",
            "AP: 0.8550\n",
            "Precision: 0.7469\n",
            "Recall: 0.8658\n",
            "F1-Score: [0.6329, 0.8959, 0.8001, 0.8330]\n",
            "\n",
            "Metrics saved to c:\\Users\\Pongo\\OneDrive\\Documents\\~Cornel\\~Ideas n Innovation\\Project\\25-4-22 -- Parkinson Unika\\results\\Metrics\\metrics_YOLOv5l_2025-05-08_00-06-26.txt\n",
            "Validation plots saved to c:\\Users\\Pongo\\OneDrive\\Documents\\~Cornel\\~Ideas n Innovation\\Project\\25-4-22 -- Parkinson Unika\\results\\Validation_Plots\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "\n",
        "# Define base local path\n",
        "local_base_path = os.getcwd()  # or set your own path: e.g., \"D:/YOLOProject\"\n",
        "results_dirs = os.path.join(local_base_path, \"results\")\n",
        "os.makedirs(results_dirs, exist_ok=True)\n",
        "\n",
        "# Validate the model\n",
        "val_results = model.val()\n",
        "\n",
        "# Create a subfolder for metrics\n",
        "output_dir = os.path.join(results_dirs, \"Metrics\")\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Collect metrics\n",
        "metrics = {\n",
        "    \"AP50\": val_results.box.map50,         # Mean AP at IoU=0.50\n",
        "    \"AP\": val_results.box.map,            # Mean AP at IoU=0.50:0.95\n",
        "    \"Precision\": val_results.box.mp,      # Mean Precision\n",
        "    \"Recall\": val_results.box.mr,         # Mean Recall\n",
        "    \"F1-Score\": val_results.box.f1,       # F1 score (list per class, optional)\n",
        "}\n",
        "\n",
        "# Create timestamp and model name manually if not already defined\n",
        "current_time = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "date_now = datetime.now().strftime(\"%Y-%m-%d\")\n",
        "# model_name = model.model.cfg if hasattr(model.model, 'cfg') else \"yolov8_model\"\n",
        "\n",
        "# Save metrics to a file with header\n",
        "metrics_file_path = os.path.join(output_dir, f\"metrics_{model_name}_{current_time}.txt\")\n",
        "with open(metrics_file_path, \"w\") as f:\n",
        "    f.write(f\"Model: {model_name}\\n\")\n",
        "    f.write(f\"Validation Time: {current_time.replace('_', ' ')}\\n\\n\")\n",
        "    f.write(f\"Training Duration: {training_duration_hours:.3f} hours for {epoch} epochs\\n\\n\")  # <-- This line\n",
        "\n",
        "    for metric, value in metrics.items():\n",
        "        if isinstance(value, (list, np.ndarray)):\n",
        "            value_str = \", \".join(f\"{v:.4f}\" for v in value)\n",
        "            line = f\"{metric}: [{value_str}]\"\n",
        "        else:\n",
        "            line = f\"{metric}: {value:.4f}\"\n",
        "        f.write(line + \"\\n\")\n",
        "\n",
        "# Display metrics in console\n",
        "print(\"\\nMetrics:\")\n",
        "with open(metrics_file_path, \"r\") as f:\n",
        "    print(f.read())\n",
        "\n",
        "print(f\"Metrics saved to {metrics_file_path}\")\n",
        "\n",
        "# Save validation plots manually\n",
        "results_dir = val_results.save_dir\n",
        "if os.path.exists(results_dir):\n",
        "    destination_dir = os.path.join(results_dirs, \"Validation_Plots\")\n",
        "    os.makedirs(destination_dir, exist_ok=True)\n",
        "    os.system(f\"cp -r \\\"{results_dir}\\\" \\\"{destination_dir}\\\"\")\n",
        "    print(f\"Validation plots saved to {destination_dir}\")\n",
        "else:\n",
        "    print(\"Validation results directory not found.\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
